{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# YOLO v2\n",
    "## 基于 Tensorflow2.4 的实现\n",
    "## 使用 VOC2007 和 VOC2012 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 导包\n",
    "import os\n",
    "import struct\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from lxml import etree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 导包并测试\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.test.gpu_device_name()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1、配置参数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    参考https://github.com/pjreddie/darknet/blob/master/cfg/yolov2-voc.cfg\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Training\n",
    "        self.IMAGE_W = 416\n",
    "        self.IMAGE_H = 416\n",
    "        self.GRID_W = 13\n",
    "        self.GRID_H = 13\n",
    "        self.ANCHORS_NUM = 5\n",
    "        self.CLASSES_NUM = 20\n",
    "        self.NOOBJECT_LAMBDA = 1\n",
    "        self.OBJECT_LAMBDA = 5\n",
    "        self.CLASS_LAMBDA = 1\n",
    "        self.COORD_LAMBDA = 1\n",
    "        # 论文中提到的K-means算法得到的VOC数据集的5个box的信息\n",
    "        self.ANCHORS = [1.3221, 1.73145, 3.19275, 4.00944, 5.05587, 8.09892, 9.47112, 4.84053, 11.2364, 10.0071]\n",
    "        self.ANCHORS = np.array(self.ANCHORS)\n",
    "        self.ANCHORS = self.ANCHORS.reshape(-1, 2)\n",
    "\n",
    "        self.VOC_NAME_LABEL_CLASS = {\n",
    "            'none': (0, 'Background'),\n",
    "            'aeroplane': (1, 'Vehicle'),\n",
    "            'bicycle': (2, 'Vehicle'),\n",
    "            'bird': (3, 'Animal'),\n",
    "            'boat': (4, 'Vehicle'),\n",
    "            'bottle': (5, 'Indoor'),\n",
    "            'bus': (6, 'Vehicle'),\n",
    "            'car': (7, 'Vehicle'),\n",
    "            'cat': (8, 'Animal'),\n",
    "            'chair': (9, 'Indoor'),\n",
    "            'cow': (10, 'Animal'),\n",
    "            'diningtable': (11, 'Indoor'),\n",
    "            'dog': (12, 'Animal'),\n",
    "            'horse': (13, 'Animal'),\n",
    "            'motorbike': (14, 'Vehicle'),\n",
    "            'person': (15, 'Person'),\n",
    "            'pottedplant': (16, 'Indoor'),\n",
    "            'sheep': (17, 'Animal'),\n",
    "            'sofa': (18, 'Indoor'),\n",
    "            'train': (19, 'Vehicle'),\n",
    "            'tvmonitor': (20, 'Indoor'),\n",
    "        }\n",
    "        self.VOC_NAME_LABEL = {key:v[0] for key,v in self.VOC_NAME_LABEL_CLASS.items()}\n",
    "        self.VOC_LABEL_NAME = {v[0]:key for key,v in self.VOC_NAME_LABEL_CLASS.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2、处理和构造数据集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_example_list(path):\n",
    "    \"\"\"\n",
    "    读取训练集或验证集\n",
    "    :param path: 路径\n",
    "    :return: list\n",
    "    \"\"\"\n",
    "    with tf.io.gfile.GFile(path) as f:\n",
    "        lines = f.readlines()\n",
    "    return [lines.strip().split(' ')[0] for line in lines]\n",
    "\n",
    "def parse_xml_to_dict(xml):\n",
    "    \"\"\"\n",
    "    递归地将 xml 转化为 字典\n",
    "    :param xml: 通过解析 xml 得到的 lxml.etree 格式\n",
    "    :return: 包含 xml 的字典\n",
    "    \"\"\"\n",
    "    if len(xml) == 0:\n",
    "        return {xml.tag: xml.text}\n",
    "    result = {}\n",
    "    for child in xml:\n",
    "        child_result = parse_xml_to_dict(child)\n",
    "        if child.tag != 'object':\n",
    "            result[child.tag] = child_result[child.tag]\n",
    "        else:\n",
    "            if child.tag not in result:\n",
    "                result[child.tag] = []\n",
    "            result[child.tag].append(child_result[child.tag])\n",
    "    return {xml.tag: result}\n",
    "\n",
    "def transform(x, y, config):\n",
    "    \"\"\"\n",
    "    从数据集中生成一个 batch size 的标签值， 准备在计算损失时和预测值比较\n",
    "    :param x: 一个 batch size 的图片 (batch size, h, w, 3)\n",
    "    :param y: 一个batch size 的 label (batch size, xmin, ymin, xmax, ymax, label)\n",
    "    :param config: 配置\n",
    "    :return: batch\n",
    "        - x : 要预测的图片（batch_size, IMAGE_H, IMAGE_W, 3）\n",
    "        - detector_mask : 是否有 bounding box 在格子内预测（batch, size, GRID_W, GRID_H, anchors_num, 1）\n",
    "        - y_true_anchor_boxes : bounding box 坐标（batch_size, GRID_W, GRID_H, anchors_num, 5）\n",
    "        - y_true_class_hot : 预测类别的 one hot 编码（batch_size, GRID_W, GRID_H, anchors_num, class_num)\n",
    "        - y_true_boxes_all : 标签值（batch_size, max annotation(这里设置为100), 5）\n",
    "    \"\"\"\n",
    "    anchors = config.ANCHORS\n",
    "    anchors_num = anchors.shape[0]\n",
    "    y = y.numpy()\n",
    "    batch_size = y.shape[0]\n",
    "    detector_mask = np.zeros([batch_size, config.GRID_W, config.GRID_H, anchors_num, 1])\n",
    "    y_true_anchor_boxes = np.zeros([batch_size, config.GRID_W, config.GRID_H, anchors_num, 5])\n",
    "    y_true_class_hot = np.zeros([batch_size, config.GRID_W, config.GRID_H, anchors_num, config.CLASSES_NUM])\n",
    "    y_true_boxes_all = np.zeros(y.shape)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        boxes = y[i]\n",
    "        for j, box in enumerate(boxes):\n",
    "            w = box[2] - box[0]\n",
    "            h = box[3] - box[1]\n",
    "            cx = (box[0] + box[2])/2  # 中心点坐标\n",
    "            cy = (box[1] + box[3])/2\n",
    "\n",
    "            w *= config.GRID_W\n",
    "            h *= config.GRID_H\n",
    "            cx *= config.GRID_W\n",
    "            cy *= config.GRID_H\n",
    "\n",
    "            y_true_boxes_all[i, j] = np.array([cx, cy, w, h, box[4]])\n",
    "            if w * h <= 0:\n",
    "                continue\n",
    "            # 网格 index\n",
    "            cell_col = np.floor(cx).astype(np.int)\n",
    "            cell_row = np.floor(cy).astype(np.int)\n",
    "            # 寻找 IoU 最高的 anchor\n",
    "            anchors_w, anchors_h = anchors[:, 0], anchors[:, 1]\n",
    "            intersect = np.minimum(w, anchors_w) * np.minimum(h, anchors_h)\n",
    "            union = anchors_w * anchors_h + w * h - intersect\n",
    "            iou = intersect / union\n",
    "            anchor_best = np.argmax(iou)\n",
    "\n",
    "            class_index = int(box[4])\n",
    "            y_true_anchor_boxes[i, cell_col, cell_row, anchor_best] = [cx, cy, w, h, class_index]\n",
    "            y_true_class_hot[i, cell_col, cell_row, anchor_best, class_index-1] = 1\n",
    "            detector_mask[i, cell_col, cell_row, anchor_best] = 1\n",
    "\n",
    "    detector_mask = tf.convert_to_tensor(detector_mask, dtype='int64')\n",
    "    y_true_anchor_boxes = tf.convert_to_tensor(y_true_anchor_boxes, dtype='float32')\n",
    "    y_true_boxes_all = tf.convert_to_tensor(y_true_boxes_all, dtype='float32')\n",
    "    y_true_class_hot = tf.convert_to_tensor(y_true_class_hot, dtype='float32')\n",
    "    batch = (x, detector_mask, y_true_anchor_boxes, y_true_class_hot, y_true_boxes_all)\n",
    "    return batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 法一：先生成tfrecords，读取时再一个个的batch解析\n",
    "IMAGE_FEATURE_MAP = {\n",
    "    'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/source_id': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/key/sha256': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/format': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32), # 如果数据中存放的list长度大于1, 表示数据是不定长的, 使用VarLenFeature解析\n",
    "    'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/class/text': tf.io.VarLenFeature(tf.string),\n",
    "    'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "    'image/object/difficult': tf.io.VarLenFeature(tf.int64),\n",
    "    'image/object/truncated': tf.io.VarLenFeature(tf.int64),\n",
    "    'image/object/view': tf.io.VarLenFeature(tf.string),\n",
    "}\n",
    "\n",
    "def parse_example(serialized_example, height, width):\n",
    "    x = tf.io.parse_single_example(serialized_example, IMAGE_FEATURE_MAP)\n",
    "    x_train = tf.image.decode_jpeg(x['image/encoded'], channels=3)\n",
    "    x_train = tf.image.resize(x_train, (height,width))\n",
    "    labels = tf.cast(tf.sparse.to_dense(x['image/object/class/label']), tf.float32)\n",
    "    y_train = tf.stack([tf.sparse.to_dense(x['image/object/bbox/xmin']), # shape: [m]\n",
    "                        tf.sparse.to_dense(x['image/object/bbox/ymin']), # shape: [m]\n",
    "                        tf.sparse.to_dense(x['image/object/bbox/xmax']), # shape: [m]\n",
    "                        tf.sparse.to_dense(x['image/object/bbox/ymax']), # shape: [m]\n",
    "                        labels  # shape: [m]\n",
    "                        ], axis=1) # shape:[m, 5], m是图片中目标的个数, 每张图片的m可能不一样\n",
    "    # 每个图片最多包含100个目标\n",
    "    paddings = [[0, 100 - tf.shape(y_train)[0]], [0, 0]] # 上下左右分别填充0, 100 - tf.shape(y_train)[0], 0, 0\n",
    "    y_train = tf.pad(y_train, paddings)\n",
    "    return x_train, y_train\n",
    "\n",
    "def OB_tfrecord_dataset(dataset_path, batch_size, config, shuffle=False):\n",
    "    files = tf.data.Dataset.list_files(dataset_path)\n",
    "    dataset = files.flat_map(tf.data.TFRecordDataset)\n",
    "    dataset = dataset.map(lambda x:parse_example(x, height=config.IMAGE_H, width=config.IMAGE_W))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=500)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)  # 提前获取数据存在缓存里来减少gpu因为缺少数据而等待的情况\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 法二：即时的从硬盘读取，不用生成tfrecords，不需事先把每张图片的标签读进来\n",
    "def get_imgPath_and_annotations(data_path, years, config,\n",
    "                                image_subdirectory = 'JPEGImages',\n",
    "                                annotations_dir = 'Annotations',\n",
    "                                ignore_difficult_instances = False):\n",
    "    \"\"\"\n",
    "    得到图片的路径和box\n",
    "    :param data_path: 根目录\n",
    "    :param years: 数据集年份 2007/2012\n",
    "    :param config: 配置\n",
    "    :param image_subdirectory: 图片子文件夹\n",
    "    :param annotations_dir: 标签子文件夹\n",
    "    :param ignore_difficult_instances: 忽略复杂数据\n",
    "    :return: 路径 box\n",
    "    \"\"\"\n",
    "    annotations_list = []\n",
    "    for year in years.keys():\n",
    "        sets = years[year]\n",
    "        for _set in sets:\n",
    "            examples_path = os.path.join(data_path, year, 'ImageSets', 'Main', _set + '.txt')\n",
    "            annotations_path = os.path.join(data_path, year, annotations_dir)\n",
    "            examples_list = read_example_list(examples_path)\n",
    "            annotation_list = [os.path.join(annotations_path, example + '.xml') for example in examples_list]\n",
    "            annotations_list += annotation_list\n",
    "\n",
    "    img_names = []\n",
    "    max_obj = 200\n",
    "    annotations = []  # 存放每个图片的box\n",
    "    for path in annotations_list:\n",
    "        with tf.io.gfile.GFile(path, 'r') as f:\n",
    "            xml_str = f.read()\n",
    "        xml = etree.fromstring(xml_str)\n",
    "        data = parse_xml_to_dict(xml)['annotation']\n",
    "        width = int(data['size']['width'])\n",
    "        height = int(data['size']['height'])\n",
    "\n",
    "        boxes = []\n",
    "        if 'object' not in data:\n",
    "            continue\n",
    "        for obj in data['object']:\n",
    "            difficult = bool(int(obj['difficult']))\n",
    "            if ignore_difficult_instances and difficult:\n",
    "                continue\n",
    "            box = np.array([\n",
    "                float(obj['bndbox']['xmin']) / width,\n",
    "                float(obj['bndbox']['ymin']) / height,\n",
    "                float(obj['bndbox']['xmax']) / width,\n",
    "                float(obj['bndbox']['ymax']) / height,\n",
    "                config.VOC_NAME_LABEL[obj['name']]\n",
    "            ])\n",
    "            boxes.append(box)  # 一个图片的box可能有多个\n",
    "        boxes = np.stack(boxes)\n",
    "        annotations.append(boxes)\n",
    "\n",
    "        img_path = os.path.join(data['folder'], image_subdirectory, data['filename'])\n",
    "        img_path = os.path.join(data_dir, img_path)\n",
    "        img_names.append(img_path)\n",
    "    true_boxes = np.zeros([len(img_names), max_obj, 5])\n",
    "    for idx, boxes in enumerate(annotations):\n",
    "        true_boxes[idx, :boxes.shape[0]] = boxes\n",
    "    return img_names, true_boxes\n",
    "\n",
    "def parse_image(filename, true_boxes, img_h, img_w):\n",
    "    \"\"\"\n",
    "    得到图片和 box\n",
    "    :param filename: 图片路径\n",
    "    :param true_boxes: box\n",
    "    :param img_h: 期望图片长\n",
    "    :param img_w: 期望图片宽\n",
    "    :return: 图片 box\n",
    "    \"\"\"\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, (img_h, img_w))\n",
    "    return image, true_boxes\n",
    "\n",
    "def OB_tensor_slices_dataset(data_path, years, batch_size, config, shuffle=False):\n",
    "    img_names, boxes = get_imgPath_and_annotations(data_path, years, config)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img_names, boxes))\n",
    "    dataset = dataset.map(lambda x, y:parse_image(x, y, img_h=config.IMAGE_H, img_w=config.IMAGE_W))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=500)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)  # 提前获取数据存在缓存里来减少gpu因为缺少数据而等待的情况\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3、定义 YOLO 模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def space_to_depth(x):\n",
    "    return tf.nn.space_to_depth(x, block_size=2)\n",
    "\n",
    "def yolo(config):\n",
    "    \"\"\"\n",
    "    训练模型，即去掉最后一个卷积层，转而增加了三个3*3*1024的卷积层,集体参看yolov2-voc.cfg文件\n",
    "    :param config: 配置文件\n",
    "    :return: 网络模型\n",
    "    \"\"\"\n",
    "    input_image = tf.keras.layers.Input((config.IMAGE_H, config.IMAGE_W, 3), dtype='float32')\n",
    "    # 1\n",
    "    x = Conv2D(32, (3, 3), strides=(1, 1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "    x = BatchNormalization(name='norm_1')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "    # 2\n",
    "    x = Conv2D(64, (3, 3), strides=(1, 1), padding='same', name='conv_2', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_2')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "    # 3\n",
    "    x = Conv2D(128, (3, 3), strides=(1, 1), padding='same', name='conv_3', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_3')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 4\n",
    "    x = Conv2D(64, (1, 1), strides=(1, 1), padding='same', name='conv_4', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_4')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 5\n",
    "    x = Conv2D(128, (3, 3), strides=(1, 1), padding='same', name='conv_5', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_5')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "    # 6\n",
    "    x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_6')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 7\n",
    "    x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_7')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 8\n",
    "    x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_8')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    # 9\n",
    "    x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_9')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 10\n",
    "    x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_10')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 11\n",
    "    x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_11')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 12\n",
    "    x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_12')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 13\n",
    "    x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_13')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    skip_connection = x\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    # 14\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_14')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 15\n",
    "    x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_15')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 16\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_16')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 17\n",
    "    x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_17')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 18\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_18')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 19 把最后一层卷积层移除,添加3个1024*3*3卷积层\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_19')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 20\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_20')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 21 passthrough层\n",
    "    skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
    "    skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "    skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "    skip_connection = Lambda(space_to_depth)(skip_connection)\n",
    "    x = concatenate([skip_connection, x])\n",
    "    # 22\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_22')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    # 23 1*1的卷积层生成预测输出\n",
    "    x = Conv2D(config.ANCHORS_NUM * (4 + 1 + config.CLASSES_NUM), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
    "    output = Reshape((config.GRID_W, config.GRID_H, config.ANCHORS_NUM, 4 + 1 + config.CLASSES_NUM))(x)\n",
    "\n",
    "    yolo_model = keras.models.Model(input_image, output)\n",
    "    return yolo_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4、加载预训练权重"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class WeightReader:\n",
    "    def __init__(self, weight_file):\n",
    "        with open(weight_file, 'rb') as w_f:\n",
    "            major, = struct.unpack('i', w_f.read(4))\n",
    "            minor, = struct.unpack('i', w_f.read(4))\n",
    "            revision, = struct.unpack('i', w_f.read(4))\n",
    "            if (major*10+minor) >=2 and major < 1000 and minor < 1000:\n",
    "                w_f.read(8)\n",
    "            else:\n",
    "                w_f.read(4)\n",
    "            transpose = (major > 1000) or (minor > 1000)\n",
    "            binary = w_f.read()\n",
    "        self.offset = 0\n",
    "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
    "\n",
    "    def read_bytes(self, size):\n",
    "        self.offset = self.offset + size\n",
    "        return self.all_weights[self.offset-size:self.offset]\n",
    "\n",
    "    def load_weights(self, yolo_model, conv_num=23, if_last=False):\n",
    "        conv_num_read = conv_num\n",
    "        if not if_last:\n",
    "            conv_num_read = conv_num - 1\n",
    "\n",
    "        for i in range(1, conv_num + 1):\n",
    "            try:\n",
    "                conv_layer = yolo_model.get_layer('conv_' + str(i))\n",
    "                if i < conv_num:\n",
    "                    norm_layer = yolo_model.get_layer('norm_' + str(i))\n",
    "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "                    beta = self.read_bytes(size)  # bias\n",
    "                    gamma = self.read_bytes(size)  # scale\n",
    "                    mean = self.read_bytes(size)  # mean\n",
    "                    var = self.read_bytes(size)  # variance\n",
    "                    weights = norm_layer.set_weights([gamma, beta, mean, var])\n",
    "                if len(conv_layer.get_weights()) > 1:\n",
    "                    bias = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                    kernel = kernel.transpose([2, 3, 1, 0])\n",
    "                    conv_layer.set_weights([kernel, bias])\n",
    "                else:\n",
    "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                    kernel = kernel.transpose([2,3,1,0])\n",
    "                    conv_layer.set_weights([kernel])\n",
    "            except ValueError:\n",
    "                print(\"no convolution #\" + str(i))\n",
    "\n",
    "        if not if_last:\n",
    "          layer = yolo_model.layers[-2] # last convolutional layer\n",
    "          layer.trainable = True\n",
    "          weights = layer.get_weights()\n",
    "          new_kernel = np.random.normal(size=weights[0].shape)/(13*13)\n",
    "          new_bias = np.random.normal(size=weights[1].shape)/(13*13)\n",
    "          layer.set_weights([new_kernel, new_bias])\n",
    "\n",
    "    def reset(self):\n",
    "        self.offset = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5、IoU 和 损失函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cal_iou(x1, y1, w1, h1, x2, y2, w2, h2):\n",
    "    \"\"\"\n",
    "    计算 box1 和 box2 的 IoU\n",
    "    \"\"\"\n",
    "    xmin1 = x1 - 0.5 * w1\n",
    "    xmax1 = x1 + 0.5 * w1\n",
    "    ymin1 = y1 - 0.5 * h1\n",
    "    ymax1 = y1 + 0.5 * h1\n",
    "    xmin2 = x2 - 0.5 * w2\n",
    "    xmax2 = x2 + 0.5 * w2\n",
    "    ymin2 = y2 - 0.5 * h2\n",
    "    ymax2 = y2 + 0.5 * h2\n",
    "    inter_x = np.minimum(xmax1, xmax2) - np.maximum(xmin1, xmin2)\n",
    "    inter_y = np.minimum(ymax1, ymax2) - np.maximum(ymin1, ymin2)\n",
    "    inter = inter_x * inter_y\n",
    "    union = w1 * h1 + w2 * h2 - inter\n",
    "    iou = inter / (union + 1e-6)\n",
    "    return iou\n",
    "\n",
    "def yolo_loss(detector_mask, y_true_anchor_boxes, y_true_class_hot, y_true_boxes_all, y_pred, config):\n",
    "    \"\"\"\n",
    "    损失函数\n",
    "    :param detector_mask: shape(batch_size, GRID_W, GRID_H, anchors_count, 1)\n",
    "    :param y_true_anchor_boxes: shape(batch_size, GRID_W, GRID_H, anchors_count, 5)\n",
    "    :param y_true_class_hot: one hot编码 shape(batch_size, GRID_W, GRID_H, anchors_count, class_count)\n",
    "    :param y_true_boxes_all: (x, y, w, h, c)\n",
    "    :param y_pred: shape(batch_size, GRID_W, GRID_H, anchors_count, 5 + labels count)\n",
    "    :param config: 配置\n",
    "    :return: loss\n",
    "    \"\"\"\n",
    "    # 0-GRID_W -1 / GRID_H -1\n",
    "    cell_coord_x = tf.cast(tf.reshape(tf.tile(tf.range(config.GRID_W), [config.GRID_H]), (1, config.GRID_H, config.GRID_W, 1, 1)), tf.float32)\n",
    "    cell_coord_y = tf.transpose(cell_coord_x, (0,2,1,3,4))\n",
    "    cell_coords = tf.tile(tf.concat([cell_coord_x, cell_coord_y], -1), [y_pred.shape[0], 1, 1, 5, 1])\n",
    "\n",
    "    # 0-GRID_W / GRID_H\n",
    "    anchors = config.ANCHORS\n",
    "\n",
    "    # 0-GRID_W / GRID_H\n",
    "    pred_xy = K.sigmoid(y_pred[:,:,:,:,0:2])\n",
    "    pred_xy = pred_xy + cell_coords\n",
    "    pred_wh = K.exp(y_pred[:,:,:,:,2:4]) * anchors\n",
    "\n",
    "    # 1、坐标损失（coordinate loss）\n",
    "    # 根据gt的wh计算系数，系数作用是w和h值越小，损失系数越大，可以更好地学习尺度较小的box\n",
    "    lambda_wh = K.expand_dims(2-(y_true_anchor_boxes[:,:,:,:,2]/config.GRID_W) * (y_true_anchor_boxes[:,:,:,:,3]/config.GRID_H))\n",
    "    detector_mask = K.cast(detector_mask, tf.float32)  # batch_size, GRID_W, GRID_H, n_anchors, 1\n",
    "    n_objs = K.sum(K.cast(detector_mask>0, tf.float32))\n",
    "    # 基于预测值计算坐标损失\n",
    "    y_txy = y_true_anchor_boxes[...,0:2] - cell_coords\n",
    "    y_twh = K.log(y_true_anchor_boxes[...,2:4]*1.0/anchors + 1e-16)\n",
    "    pred_txy = K.sigmoid(y_pred[:,:,:,:,0:2])\n",
    "    pred_twh = y_pred[:,:,:,:,2:4]\n",
    "    loss_xy = config.COORD_LAMBDA * K.sum(detector_mask * K.square(y_txy - pred_txy)) / (n_objs + 1e-6)\n",
    "    loss_wh = config.COORD_LAMBDA * K.sum(lambda_wh * detector_mask * K.square(y_twh - pred_twh)) / (n_objs + 1e-6)\n",
    "    loss_coord = loss_xy + loss_wh\n",
    "\n",
    "    # 2、类别损失\n",
    "    pred_class = K.softmax(y_pred[:,:,:,:,5:])\n",
    "    loss_cls = detector_mask * K.square(y_true_class_hot - pred_class)\n",
    "    loss_cls = config.CLASS_LAMBDA * K.sum(loss_cls) / (n_objs + 1e-6)\n",
    "\n",
    "    # 3、bounding box置信度损失\n",
    "    # 3.1、包含目标的预测的bounding box置信度损失\n",
    "    # 预测值和标记值的 IoU\n",
    "    x1 = y_true_anchor_boxes[...,0]\n",
    "    y1 = y_true_anchor_boxes[...,1]\n",
    "    w1 = y_true_anchor_boxes[...,2]\n",
    "    h1 = y_true_anchor_boxes[...,3]\n",
    "    x2 = pred_xy[...,0]\n",
    "    y2 = pred_xy[...,1]\n",
    "    w2 = pred_wh[...,0]\n",
    "    h2 = pred_wh[...,1]\n",
    "    iou = cal_iou(x1, y1, w1, h1, x2, y2, w2, h2)\n",
    "    iou = K.expand_dims(iou, -1)\n",
    "    # 使用 IoU 计算置信度的 target\n",
    "    pred_conf = K.sigmoid(y_pred[...,4:5])\n",
    "    loss_conf_obj = config.OBJECT_LAMBDA * K.sum(detector_mask * K.square(iou - pred_conf)) / (n_objs + 1e-6)\n",
    "    # 3.2、不包含目标的预测的bounding box置信度损失\n",
    "    # 预测值bounding box的xmin, ymin, xmax, ymax\n",
    "    pred_xy = K.expand_dims(pred_xy, 4)  # shape(batch_size, GRID_W, GRID_H, n_anchors, 1, 2)\n",
    "    pred_wh = K.expand_dims(pred_wh, 4)\n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_min = pred_xy - pred_wh_half\n",
    "    pred_max = pred_xy + pred_wh_half\n",
    "    # 标记值bounding box的xmin, ymin, xmax, ymax\n",
    "    true_boxes_shape = K.int_shape(y_true_boxes_all)\n",
    "    true_boxes_grid = K.reshape(y_true_boxes_all, [true_boxes_shape[0], 1, 1, 1, true_boxes_shape[1], true_boxes_shape[2]])\n",
    "    true_xy = true_boxes_grid[...,0:2]  # shape(batch_size, 1, 1, 1, max_annotation, 2)\n",
    "    true_wh = true_boxes_grid[...,2:4]  # shape(batch_size, 1, 1, 1, max_annotation, 2)\n",
    "    true_wh_half = true_wh * 0.5\n",
    "    true_min = true_xy - true_wh_half\n",
    "    true_max = true_xy + true_wh_half\n",
    "    # 计算每一个预测的box与所有标记的box的IoU，找出最大的IOU，如果小于阈值(0.6,并且不负责GT，根据1 - detector_mask)，该预测的box就加入noobj，计算置信度损失\n",
    "    intersect_min = K.maximum(pred_min, true_min)  # shape(batch_size, GRID_W, GRID_H, n_anchors, max_annotation, 2)\n",
    "    intersect_max = K.minimum(pred_max, true_max)  # shape(batch_size, GRID_W, GRID_H, n_anchors, max_annotation, 2)\n",
    "    intersect_wh = K.maximum(intersect_max - intersect_min, 0.)  # shape(batch_size, GRID_W, GRID_H, n_anchors, max_annotation, 1)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]  # shape(batch_size, GRID_W, GRID_H, n_anchors, max_annotation, 1)\n",
    "    pred_area = pred_wh[..., 0] * pred_wh[..., 1]  # shape(batch_size, GRID_W, GRID_H, n_anchors, 1, 1)\n",
    "    true_area = true_wh[..., 0] * true_wh[..., 1]  # shape(batch_size, GRID_W, GRID_H, n_anchors, max_annotation, 1)\n",
    "    union_area = pred_area + true_area - intersect_area\n",
    "    iou_score = intersect_area / union_area  # shape(batch_size, GRID_W, GRID_H, n_anchors, max_annotation, 1)\n",
    "    best_iou = K.max(iou_score, axis=4)  # Best IOU scores.\n",
    "    best_iou = K.expand_dims(best_iou)  # shape(batch_size, GRID_W, GRID_H, n_anchors, 1)\n",
    "    # 计算无目标损失\n",
    "    no_object_detection = K.cast(best_iou < 0.6, K.dtype(best_iou))\n",
    "    noobj_mask = no_object_detection * (1 - detector_mask)\n",
    "    n_noobj  = K.sum(tf.cast(noobj_mask  > 0.0, tf.float32))\n",
    "    loss_conf_noobj =  config.NOOBJECT_LAMBDA * K.sum(noobj_mask * K.square(-pred_conf)) / (n_noobj + 1e-6)\n",
    "    # 4、三种损失汇总\n",
    "    loss_conf = loss_conf_noobj + loss_conf_obj\n",
    "    loss = loss_conf + loss_cls + loss_coord\n",
    "    sub_loss = [loss_conf, loss_cls, loss_coord]\n",
    "    return loss, sub_loss\n",
    "\n",
    "def save_best_weights(model, name, val_loss_avg):\n",
    "    \"\"\"\n",
    "    保存最好的权重\n",
    "    \"\"\"\n",
    "    name = name + '_' + str(val_loss_avg) + '.h5'\n",
    "    path_name = os.path.join('weight/', name)\n",
    "    model.save_weights(path_name)\n",
    "    return path_name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6、开始训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "data_dir = 'VOCdevkit'\n",
    "val_set = {'VOC2012':['val']}\n",
    "train_set = {'VOC2007':['train', 'val', 'test'], 'VOC2012':['train']}\n",
    "\n",
    "batch_size = 6\n",
    "num_epochs = 30\n",
    "num_iterations = 30\n",
    "cfg = Config()\n",
    "model_weight_path = 'weight/yolo.weights'\n",
    "n_progress = 20  # 进度条份数\n",
    "\n",
    "dataset_train = OB_tensor_slices_dataset(data_dir, train_set, batch_size, cfg, shuffle=True)\n",
    "dataset_val = OB_tensor_slices_dataset(data_dir, val_set, batch_size, cfg, shuffle=False)\n",
    "len_batches_train = tf.data.experimental.cardinality(dataset_train).numpy()\n",
    "len_batches_val = tf.data.experimental.cardinality(dataset_val).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 准备模型\n",
    "weight_reader = WeightReader(model_weight_path)\n",
    "model = yolo(cfg)\n",
    "weight_reader.load_weights(model)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 准备训练\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "best_val_loss = 1e6\n",
    "initial_learning_rate = 2e-5\n",
    "decay_epochs = 30 * num_iterations\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=decay_epochs,\n",
    "    decay_rate=0.5,\n",
    "    staircase=True\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, bata_1=0.9, bata_2=0.999, epsilon=1e-8)\n",
    "train_layers = ['conv_22', 'norm_22', 'conv_23']\n",
    "train_vars = []\n",
    "for name in train_layers:\n",
    "     train_vars += model.get_layer(name).trainable_variables"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 开始训练\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = []\n",
    "    epoch_sub_loss = []\n",
    "    epoch_val_loss = []\n",
    "    epoch_val_sub_loss = []\n",
    "\n",
    "    # train\n",
    "    for bs_idx, (x, y) in enumerate(dataset_train):\n",
    "        x, detector_mask, y_true_anchor_boxes, y_true_class_hot, y_true_boxes_all = transform(x, y, cfg)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x, training=True)\n",
    "            loss, sub_loss = yolo_loss(detector_mask, y_true_anchor_boxes, y_true_class_hot, y_true_boxes_all, y_pred, cfg)\n",
    "            _loss = loss * 0.01\n",
    "        grads = tape.gradient(_loss, train_vars)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, train_vars))\n",
    "        epoch_loss.append(loss)\n",
    "        epoch_sub_loss.append(sub_loss)\n",
    "        if (bs_idx + 1) % (math.ceil(num_iterations / n_progress)) == 0:\n",
    "            print('-', end='')\n",
    "        if (bs_idx + 1) == num_iterations:\n",
    "            break\n",
    "\n",
    "    # val\n",
    "    for bs_idx, (x,y) in enumerate(dataset_val):\n",
    "        x, detector_mask, y_true_anchor_boxes, y_true_class_hot, y_true_boxes_all = transform(x, y, cfg)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x, training=False)\n",
    "            loss, sub_loss = yolo_loss(detector_mask, y_true_anchor_boxes, y_true_class_hot, y_true_boxes_all, y_pred, cfg)\n",
    "        epoch_val_loss.append(loss)\n",
    "        epoch_val_sub_loss.append(sub_loss)\n",
    "        print('-', end='')\n",
    "        if (bs_idx+1)==1:\n",
    "            break\n",
    "\n",
    "    # 记录\n",
    "    loss_avg = np.mean(np.array(epoch_loss))\n",
    "    sub_loss_avg = np.mean(np.array(epoch_sub_loss), axis=0)\n",
    "    val_loss_avg = np.mean(np.array(epoch_val_loss))\n",
    "    val_sub_loss_avg = np.mean(np.array(epoch_val_sub_loss), axis=0)\n",
    "\n",
    "    train_loss_history.append(loss_avg)\n",
    "    val_loss_history.append(val_loss_avg)\n",
    "\n",
    "    if loss_avg < best_val_loss:\n",
    "        best_model_path = save_best_weights(model, 'yolo_epoch%d' % epoch, loss_avg)\n",
    "        best_val_loss = loss_avg\n",
    "save_best_weights(model, 'yolo_epoch_final', 666)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 开始测试"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.load_weights(best_model_path)\n",
    "for bs_idx, (x,y) in enumerate(dataset_val):\n",
    "    x, detector_mask, y_true_anchor_boxes, y_true_class_hot, y_true_boxes_all = transform(x, y, cfg)\n",
    "    score_threshold = 0.5  # 根据box_conf * box_class_prob筛选boxes\n",
    "    iou_threshold = 0.45  # 对boxes做NMS时的阈值\n",
    "\n",
    "    input_image = x[0]\n",
    "    y_pred = model.predict_on_batch(tf.expand_dims(input_image, 0))\n",
    "    cell_coord_x = tf.cast(tf.reshape(tf.tile(tf.range(cfg.GRID_W), [cfg.GRID_H]), (1, cfg.GRID_H, cfg.GRID_W, 1, 1)), tf.float32)\n",
    "    cell_coord_y = tf.transpose(cell_coord_x, (0,2,1,3,4))\n",
    "    cell_coords = tf.tile(tf.concat([cell_coord_x, cell_coord_y], -1), [y_pred.shape[0], 1, 1, 5, 1])\n",
    "    anchors = cfg.ANCHORS\n",
    "\n",
    "    pred_xy = K.sigmoid(y_pred[:,:,:,:,0:2])\n",
    "    pred_xy = pred_xy + cell_coords\n",
    "    pred_wh = K.exp(y_pred[:,:,:,:,2:4]) * anchors\n",
    "\n",
    "    box_conf = K.sigmoid(y_pred[:,:,:,:,4:5])\n",
    "    box_class_prob = K.softmax(y_pred[:,:,:,:,5:])\n",
    "    box_xy1 = pred_xy - 0.5 * pred_wh\n",
    "    box_xy2 = pred_xy + 0.5 * pred_wh\n",
    "    boxes = K.concatenate((box_xy1, box_xy2), axis=-1)\n",
    "\n",
    "    box_scores = box_conf * box_class_prob\n",
    "\n",
    "    box_classes = K.argmax(box_scores, axis=-1) # 最好的分数的 index\n",
    "    box_class_scores = K.max(box_scores, axis=-1) # 最好的分数\n",
    "    prediction_mask = box_class_scores >= score_threshold\n",
    "    boxes = tf.boolean_mask(boxes, prediction_mask)\n",
    "    scores = tf.boolean_mask(box_class_scores, prediction_mask)\n",
    "    classes = tf.boolean_mask(box_classes, prediction_mask)\n",
    "\n",
    "    # NMS（非极大值抑制）\n",
    "    selected_idx = tf.image.non_max_suppression(boxes, scores, 50, iou_threshold=iou_threshold)\n",
    "    boxes = K.gather(boxes, selected_idx)  # [n, 4]\n",
    "    scores = K.gather(scores, selected_idx)  # [n,]\n",
    "    classes = K.gather(classes, selected_idx)  # [n,]\n",
    "    _boxes = K.stack((0.5*(boxes[:,0] + boxes[:,2]),\n",
    "                      0.5*(boxes[:,1] + boxes[:,3]),\n",
    "                      boxes[:,2] - boxes[:,0],\n",
    "                      boxes[:,3] - boxes[:,1]),\n",
    "                      axis=-1) # x1, y1, x2, y2 ==> cx, cy, w, h\n",
    "\n",
    "    # 画图\n",
    "    fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "    img = input_image.numpy()\n",
    "    boxes = _boxes.numpy().reshape(-1, 4)\n",
    "    labels = classes.numpy()\n",
    "    scores = scores.numpy()\n",
    "\n",
    "    ax.show(img)\n",
    "    IMG_H, IMG_W = img.shape[0: 2]\n",
    "    colors = ['r', 'orange', 'g', 'b', 'pink', 'purple']\n",
    "    count = 0\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        cx, cy, w, h = box\n",
    "        if w * h <= 0:\n",
    "            continue\n",
    "        count += 1\n",
    "        cx = cx / cfg.GRID_W * IMG_W\n",
    "        cy = cy/cfg.GRID_H * IMG_H\n",
    "        w = w/cfg.GRID_W * IMG_W\n",
    "        h = h/cfg.GRID_H * IMG_H\n",
    "        name = cfg.VOC_LABEL_NAME[label+1]\n",
    "        ax.scatter(cx, cy, s=10, c='yellow')\n",
    "        text = ' No:%d' % count + '_'+ name + ' %.3f' % score\n",
    "        ax.text(cx-w/2, cy+h/2, text, fontdict={'size':15, 'color':colors[count-1]})\n",
    "        rect = patches.Rectangle((cx-w/2,cy-h/2), w, h, edgecolor=colors[count-1], linewidth=3.0, facecolor='none')\n",
    "        ax.add_patch(rect)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}