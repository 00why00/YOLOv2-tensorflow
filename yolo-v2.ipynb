{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# YOLO v2\n",
    "## 基于 Tensorflow2.4 的实现\n",
    "## 使用 VOC2007 和 VOC2012 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 导包\n",
    "import os\n",
    "import struct\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "'/device:GPU:0'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导包并测试\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1、配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    参考https://github.com/pjreddie/darknet/blob/master/cfg/yolov2-voc.cfg\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Training\n",
    "        self.IMAGE_W = 416\n",
    "        self.IMAGE_H = 416\n",
    "        self.GRID_W = 13\n",
    "        self.GRID_H = 13\n",
    "        self.ANCHORS_NUM = 5\n",
    "        self.CLASSES_NUM = 20\n",
    "        self.NOOBJECT_LAMBDA = 1\n",
    "        self.OBJECT_LAMBDA = 5\n",
    "        self.CLASS_LAMBDA = 1\n",
    "        self.COORD_LAMBDA = 1\n",
    "        # 论文中提到的K-means算法得到的VOC数据集的5个box的信息\n",
    "        self.ANCHORS = [1.3221, 1.73145, 3.19275, 4.00944, 5.05587, 8.09892, 9.47112, 4.84053, 11.2364, 10.0071]\n",
    "        self.ANCHORS = np.array(self.ANCHORS)\n",
    "        self.ANCHORS = self.ANCHORS.reshape(-1, 2)\n",
    "\n",
    "        self.VOC_NAME_LABEL_CLASS = {\n",
    "            'none': (0, 'Background'),\n",
    "            'aeroplane': (1, 'Vehicle'),\n",
    "            'bicycle': (2, 'Vehicle'),\n",
    "            'bird': (3, 'Animal'),\n",
    "            'boat': (4, 'Vehicle'),\n",
    "            'bottle': (5, 'Indoor'),\n",
    "            'bus': (6, 'Vehicle'),\n",
    "            'car': (7, 'Vehicle'),\n",
    "            'cat': (8, 'Animal'),\n",
    "            'chair': (9, 'Indoor'),\n",
    "            'cow': (10, 'Animal'),\n",
    "            'diningtable': (11, 'Indoor'),\n",
    "            'dog': (12, 'Animal'),\n",
    "            'horse': (13, 'Animal'),\n",
    "            'motorbike': (14, 'Vehicle'),\n",
    "            'person': (15, 'Person'),\n",
    "            'pottedplant': (16, 'Indoor'),\n",
    "            'sheep': (17, 'Animal'),\n",
    "            'sofa': (18, 'Indoor'),\n",
    "            'train': (19, 'Vehicle'),\n",
    "            'tvmonitor': (20, 'Indoor'),\n",
    "        }\n",
    "        self.VOC_NAME_LABEL = {key:v[0] for key,v in self.VOC_NAME_LABEL_CLASS.items()}\n",
    "        self.VOC_LABEL_NAME = {v[0]:key for key,v in self.VOC_NAME_LABEL_CLASS.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2、处理和构造数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_example_list(path):\n",
    "    \"\"\"\n",
    "    读取训练集或验证集\n",
    "    :param path: 路径\n",
    "    :return: list\n",
    "    \"\"\"\n",
    "    with tf.io.gfile.GFile(path) as f:\n",
    "        lines = f.readlines()\n",
    "    return [line.strip().split(' ')[0] for line in lines]\n",
    "\n",
    "def parse_xml_to_dict(xml):\n",
    "    \"\"\"\n",
    "    递归地将 xml 转化为 字典\n",
    "    :param xml: 通过解析 xml 得到的 lxml.etree 格式\n",
    "    :return: 包含 xml 的字典\n",
    "    \"\"\"\n",
    "    if len(xml) == 0:\n",
    "        return {xml.tag: xml.text}\n",
    "    result = {}\n",
    "    for child in xml:\n",
    "        child_result = parse_xml_to_dict(child)\n",
    "        if child.tag != 'object':\n",
    "            result[child.tag] = child_result[child.tag]\n",
    "        else:\n",
    "            if child.tag not in result:\n",
    "                result[child.tag] = []\n",
    "            result[child.tag].append(child_result[child.tag])\n",
    "    return {xml.tag: result}\n",
    "\n",
    "def transform(x, y, config):\n",
    "    \"\"\"\n",
    "    从数据集中生成一个 batch size 的标签值， 准备在计算损失时和预测值比较\n",
    "    :param x: 一个 batch size 的图片 (batch size, h, w, 3)\n",
    "    :param y: 一个batch size 的 label (batch size, xmin, ymin, xmax, ymax, label)\n",
    "    :param config: 配置\n",
    "    :return: batch\n",
    "        - x : 要预测的图片（batch_size, IMAGE_H, IMAGE_W, 3）\n",
    "        - detector_mask : 是否有 bounding box 在格子内预测（batch, size, GRID_W, GRID_H, anchors_num, 1）\n",
    "        - y_true_anchor_boxes : bounding box 坐标（batch_size, GRID_W, GRID_H, anchors_num, 5）\n",
    "        - y_true_class_hot : 预测类别的 one hot 编码（batch_size, GRID_W, GRID_H, anchors_num, class_num)\n",
    "        - y_true_boxes_all : 标签值（batch_size, max annotation(这里设置为100), 5）\n",
    "    \"\"\"\n",
    "    anchors = config.ANCHORS\n",
    "    anchors_num = anchors.shape[0]\n",
    "    y = y.numpy()\n",
    "    batch_size = y.shape[0]\n",
    "    detector_mask = np.zeros([batch_size, config.GRID_W, config.GRID_H, anchors_num, 1])\n",
    "    y_true_anchor_boxes = np.zeros([batch_size, config.GRID_W, config.GRID_H, anchors_num, 5])\n",
    "    y_true_class_hot = np.zeros([batch_size, config.GRID_W, config.GRID_H, anchors_num, config.CLASSES_NUM])\n",
    "    y_true_boxes_all = np.zeros(y.shape)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        boxes = y[i]\n",
    "        for j, box in enumerate(boxes):\n",
    "            w = box[2] - box[0]\n",
    "            h = box[3] - box[1]\n",
    "            cx = (box[0] + box[2])/2  # 中心点坐标\n",
    "            cy = (box[1] + box[3])/2\n",
    "\n",
    "            w *= config.GRID_W\n",
    "            h *= config.GRID_H\n",
    "            cx *= config.GRID_W\n",
    "            cy *= config.GRID_H\n",
    "\n",
    "            y_true_boxes_all[i, j] = np.array([cx, cy, w, h, box[4]])\n",
    "            if w * h <= 0:\n",
    "                continue\n",
    "            # 网格 index\n",
    "            cell_col = np.floor(cx).astype(np.int)\n",
    "            cell_row = np.floor(cy).astype(np.int)\n",
    "            # 寻找 IoU 最高的 anchor\n",
    "            anchors_w, anchors_h = anchors[:, 0], anchors[:, 1]\n",
    "            intersect = np.minimum(w, anchors_w) * np.minimum(h, anchors_h)\n",
    "            union = anchors_w * anchors_h + w * h - intersect\n",
    "            iou = intersect / union\n",
    "            anchor_best = np.argmax(iou)\n",
    "\n",
    "            class_index = int(box[4])\n",
    "            y_true_anchor_boxes[i, cell_col, cell_row, anchor_best] = [cx, cy, w, h, class_index]\n",
    "            y_true_class_hot[i, cell_col, cell_row, anchor_best, class_index-1] = 1\n",
    "            detector_mask[i, cell_col, cell_row, anchor_best] = 1\n",
    "\n",
    "    detector_mask = tf.convert_to_tensor(detector_mask, dtype='int64')\n",
    "    y_true_anchor_boxes = tf.convert_to_tensor(y_true_anchor_boxes, dtype='float32')\n",
    "    y_true_boxes_all = tf.convert_to_tensor(y_true_boxes_all, dtype='float32')\n",
    "    y_true_class_hot = tf.convert_to_tensor(y_true_class_hot, dtype='float32')\n",
    "    batch = (x, detector_mask, y_true_anchor_boxes, y_true_class_hot, y_true_boxes_all)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 法一：先生成tfrecords，读取时再一个个的batch解析\n",
    "IMAGE_FEATURE_MAP = {\n",
    "    'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/source_id': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/key/sha256': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/format': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32), # 如果数据中存放的list长度大于1, 表示数据是不定长的, 使用VarLenFeature解析\n",
    "    'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/class/text': tf.io.VarLenFeature(tf.string),\n",
    "    'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "    'image/object/difficult': tf.io.VarLenFeature(tf.int64),\n",
    "    'image/object/truncated': tf.io.VarLenFeature(tf.int64),\n",
    "    'image/object/view': tf.io.VarLenFeature(tf.string),\n",
    "}\n",
    "\n",
    "def parse_example(serialized_example, height, width):\n",
    "    x = tf.io.parse_single_example(serialized_example, IMAGE_FEATURE_MAP)\n",
    "    x_train = tf.image.decode_jpeg(x['image/encoded'], channels=3)\n",
    "    x_train = tf.image.resize(x_train, (height,width))\n",
    "    labels = tf.cast(tf.sparse.to_dense(x['image/object/class/label']), tf.float32)\n",
    "    y_train = tf.stack([tf.sparse.to_dense(x['image/object/bbox/xmin']), # shape: [m]\n",
    "                        tf.sparse.to_dense(x['image/object/bbox/ymin']), # shape: [m]\n",
    "                        tf.sparse.to_dense(x['image/object/bbox/xmax']), # shape: [m]\n",
    "                        tf.sparse.to_dense(x['image/object/bbox/ymax']), # shape: [m]\n",
    "                        labels  # shape: [m]\n",
    "                        ], axis=1) # shape:[m, 5], m是图片中目标的个数, 每张图片的m可能不一样\n",
    "    # 每个图片最多包含100个目标\n",
    "    paddings = [[0, 100 - tf.shape(y_train)[0]], [0, 0]] # 上下左右分别填充0, 100 - tf.shape(y_train)[0], 0, 0\n",
    "    y_train = tf.pad(y_train, paddings)\n",
    "    return x_train, y_train\n",
    "\n",
    "def OB_tfrecord_dataset(dataset_path, batch_size, config, shuffle=False):\n",
    "    files = tf.data.Dataset.list_files(dataset_path)\n",
    "    dataset = files.flat_map(tf.data.TFRecordDataset)\n",
    "    dataset = dataset.map(lambda x:parse_example(x, height=config.IMAGE_H, width=config.IMAGE_W))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=500)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)  # 提前获取数据存在缓存里来减少gpu因为缺少数据而等待的情况\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 法二：即时的从硬盘读取，不用生成tfrecords，不需事先把每张图片的标签读进来\n",
    "def get_imgPath_and_annotations(data_path, years, config,\n",
    "                                image_subdirectory = 'JPEGImages',\n",
    "                                annotations_dir = 'Annotations',\n",
    "                                ignore_difficult_instances = False):\n",
    "    \"\"\"\n",
    "    得到图片的路径和box\n",
    "    :param data_path: 根目录\n",
    "    :param years: 数据集年份 2007/2012\n",
    "    :param config: 配置\n",
    "    :param image_subdirectory: 图片子文件夹\n",
    "    :param annotations_dir: 标签子文件夹\n",
    "    :param ignore_difficult_instances: 忽略复杂数据\n",
    "    :return: 路径 box\n",
    "    \"\"\"\n",
    "    annotations_list = []\n",
    "    for year in years.keys():\n",
    "        sets = years[year]\n",
    "        for _set in sets:\n",
    "            examples_path = os.path.join(data_path, year, 'ImageSets', 'Main', _set + '.txt')\n",
    "            annotations_path = os.path.join(data_path, year, annotations_dir)\n",
    "            examples_list = read_example_list(examples_path)\n",
    "            annotation_list = [os.path.join(annotations_path, example + '.xml') for example in examples_list]\n",
    "            annotations_list += annotation_list\n",
    "\n",
    "    img_names = []\n",
    "    max_obj = 200\n",
    "    annotations = []  # 存放每个图片的box\n",
    "    for path in annotations_list:\n",
    "        with tf.io.gfile.GFile(path, 'r') as f:\n",
    "            xml_str = f.read()\n",
    "        xml = etree.fromstring(xml_str)\n",
    "        data = parse_xml_to_dict(xml)['annotation']\n",
    "        width = int(data['size']['width'])\n",
    "        height = int(data['size']['height'])\n",
    "\n",
    "        boxes = []\n",
    "        if 'object' not in data:\n",
    "            continue\n",
    "        for obj in data['object']:\n",
    "            difficult = bool(int(obj['difficult']))\n",
    "            if ignore_difficult_instances and difficult:\n",
    "                continue\n",
    "            box = np.array([\n",
    "                float(obj['bndbox']['xmin']) / width,\n",
    "                float(obj['bndbox']['ymin']) / height,\n",
    "                float(obj['bndbox']['xmax']) / width,\n",
    "                float(obj['bndbox']['ymax']) / height,\n",
    "                config.VOC_NAME_LABEL[obj['name']]\n",
    "            ])\n",
    "            boxes.append(box)  # 一个图片的box可能有多个\n",
    "        boxes = np.stack(boxes)\n",
    "        annotations.append(boxes)\n",
    "\n",
    "        img_path = os.path.join(data['folder'], image_subdirectory, data['filename'])\n",
    "        img_path = os.path.join(data_path, img_path)\n",
    "        img_names.append(img_path)\n",
    "    true_boxes = np.zeros([len(img_names), max_obj, 5])\n",
    "    for idx, boxes in enumerate(annotations):\n",
    "        true_boxes[idx, :boxes.shape[0]] = boxes\n",
    "    return img_names, true_boxes\n",
    "\n",
    "def parse_image(filename, true_boxes, img_h, img_w):\n",
    "    \"\"\"\n",
    "    得到图片和 box\n",
    "    :param filename: 图片路径\n",
    "    :param true_boxes: box\n",
    "    :param img_h: 期望图片长\n",
    "    :param img_w: 期望图片宽\n",
    "    :return: 图片 box\n",
    "    \"\"\"\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, (img_h, img_w))\n",
    "    return image, true_boxes\n",
    "\n",
    "def OB_tensor_slices_dataset(data_path, years, batch_size, config, shuffle=False):\n",
    "    img_names, boxes = get_imgPath_and_annotations(data_path, years, config)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img_names, boxes))\n",
    "    dataset = dataset.map(lambda x, y:parse_image(x, y, img_h=config.IMAGE_H, img_w=config.IMAGE_W))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=500)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)  # 提前获取数据存在缓存里来减少gpu因为缺少数据而等待的情况\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3、定义 YOLO 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def space_to_depth(x):\n",
    "    return tf.nn.space_to_depth(x, block_size=2)\n",
    "\n",
    "def yolo(config):\n",
    "    \"\"\"\n",
    "    训练模型，即去掉最后一个卷积层，转而增加了三个3*3*1024的卷积层,集体参看yolov2-voc.cfg文件\n",
    "    :param config: 配置文件\n",
    "    :return: 网络模型\n",
    "    \"\"\"\n",
    "    input_image = tf.keras.layers.Input((config.IMAGE_H, config.IMAGE_W, 3), dtype='float32')\n",
    "    # 1\n",
    "    x = Conv2D(32, (3, 3), strides=(1, 1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "    x = BatchNormalization(name='norm_1')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    # 2\n",
    "    x = Conv2D(64, (3, 3), strides=(1, 1), padding='same', name='conv_2', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_2')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    # 3\n",
    "    x = Conv2D(128, (3, 3), strides=(1, 1), padding='same', name='conv_3', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_3')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 4\n",
    "    x = Conv2D(64, (1, 1), strides=(1, 1), padding='same', name='conv_4', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_4')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 5\n",
    "    x = Conv2D(128, (3, 3), strides=(1, 1), padding='same', name='conv_5', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_5')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    # 6\n",
    "    x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_6')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 7\n",
    "    x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_7')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 8\n",
    "    x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_8')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    # 9\n",
    "    x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_9')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 10\n",
    "    x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_10')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 11\n",
    "    x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_11')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 12\n",
    "    x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_12')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 13\n",
    "    x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_13')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    skip_connection = x\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    # 14\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_14')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 15\n",
    "    x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_15')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 16\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_16')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 17\n",
    "    x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_17')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 18\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_18')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 19 把最后一层卷积层移除,添加3个1024*3*3卷积层\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_19')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 20\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_20')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 21 passthrough层\n",
    "    skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
    "    skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "    skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "    skip_connection = Lambda(space_to_depth)(skip_connection)\n",
    "    x = concatenate([skip_connection, x])\n",
    "    # 22\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_22')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # 23 1*1的卷积层生成预测输出\n",
    "    x = Conv2D(config.ANCHORS_NUM * (4 + 1 + config.CLASSES_NUM), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
    "    output = Reshape((config.GRID_W, config.GRID_H, config.ANCHORS_NUM, 4 + 1 + config.CLASSES_NUM))(x)\n",
    "\n",
    "    yolo_model = tf.keras.models.Model(inputs=input_image, outputs=output)\n",
    "    return yolo_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4、加载预训练权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class WeightReader:\n",
    "    def __init__(self, weight_file):\n",
    "        with open(weight_file, 'rb') as w_f:\n",
    "            major, = struct.unpack('i', w_f.read(4))\n",
    "            minor, = struct.unpack('i', w_f.read(4))\n",
    "            revision, = struct.unpack('i', w_f.read(4))\n",
    "            if (major*10+minor) >=2 and major < 1000 and minor < 1000:\n",
    "                w_f.read(8)\n",
    "            else:\n",
    "                w_f.read(4)\n",
    "            transpose = (major > 1000) or (minor > 1000)\n",
    "            binary = w_f.read()\n",
    "        self.offset = 0\n",
    "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
    "\n",
    "    def read_bytes(self, size):\n",
    "        self.offset = self.offset + size\n",
    "        return self.all_weights[self.offset-size:self.offset]\n",
    "\n",
    "    def load_weights(self, yolo_model, conv_num=23, if_last=False):\n",
    "        conv_num_read = conv_num\n",
    "        if not if_last:\n",
    "            conv_num_read = conv_num - 1\n",
    "\n",
    "        for i in range(1, conv_num_read + 1):\n",
    "            try:\n",
    "                conv_layer = yolo_model.get_layer('conv_' + str(i))\n",
    "                if i < conv_num:\n",
    "                    norm_layer = yolo_model.get_layer('norm_' + str(i))\n",
    "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "                    beta = self.read_bytes(size)  # bias\n",
    "                    gamma = self.read_bytes(size)  # scale\n",
    "                    mean = self.read_bytes(size)  # mean\n",
    "                    var = self.read_bytes(size)  # variance\n",
    "                    weights = norm_layer.set_weights([gamma, beta, mean, var])\n",
    "                if len(conv_layer.get_weights()) > 1:\n",
    "                    bias = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                    kernel = kernel.transpose([2, 3, 1, 0])\n",
    "                    conv_layer.set_weights([kernel, bias])\n",
    "                else:\n",
    "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                    kernel = kernel.transpose([2,3,1,0])\n",
    "                    conv_layer.set_weights([kernel])\n",
    "            except ValueError:\n",
    "                print(\"no convolution #\" + str(i))\n",
    "\n",
    "        if not if_last:\n",
    "          layer = yolo_model.layers[-2] # last convolutional layer\n",
    "          layer.trainable = True\n",
    "          weights = layer.get_weights()\n",
    "          new_kernel = np.random.normal(size=weights[0].shape)/(13*13)\n",
    "          new_bias = np.random.normal(size=weights[1].shape)/(13*13)\n",
    "          layer.set_weights([new_kernel, new_bias])\n",
    "\n",
    "    def reset(self):\n",
    "        self.offset = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 5、IoU 和 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cal_iou(x1, y1, w1, h1, x2, y2, w2, h2):\n",
    "    \"\"\"\n",
    "    计算 box1 和 box2 的 IoU\n",
    "    \"\"\"\n",
    "    xmin1 = x1 - 0.5 * w1\n",
    "    xmax1 = x1 + 0.5 * w1\n",
    "    ymin1 = y1 - 0.5 * h1\n",
    "    ymax1 = y1 + 0.5 * h1\n",
    "    xmin2 = x2 - 0.5 * w2\n",
    "    xmax2 = x2 + 0.5 * w2\n",
    "    ymin2 = y2 - 0.5 * h2\n",
    "    ymax2 = y2 + 0.5 * h2\n",
    "    inter_x = np.minimum(xmax1, xmax2) - np.maximum(xmin1, xmin2)\n",
    "    inter_y = np.minimum(ymax1, ymax2) - np.maximum(ymin1, ymin2)\n",
    "    inter = inter_x * inter_y\n",
    "    union = w1 * h1 + w2 * h2 - inter\n",
    "    iou = inter / (union + 1e-6)\n",
    "    return iou\n",
    "\n",
    "def yolo_loss(detector_mask, y_true_anchor_boxes, y_true_class_hot, y_true_boxes_all, y_pred, config):\n",
    "    \"\"\"\n",
    "    损失函数\n",
    "    :param detector_mask: shape(batch_size, GRID_W, GRID_H, anchors_count, 1)\n",
    "    :param y_true_anchor_boxes: shape(batch_size, GRID_W, GRID_H, anchors_count, 5)\n",
    "    :param y_true_class_hot: one hot编码 shape(batch_size, GRID_W, GRID_H, anchors_count, class_count)\n",
    "    :param y_true_boxes_all: (x, y, w, h, c)\n",
    "    :param y_pred: shape(batch_size, GRID_W, GRID_H, anchors_count, 5 + labels count)\n",
    "    :param config: 配置\n",
    "    :return: loss\n",
    "    \"\"\"\n",
    "    # 0-GRID_W -1 / GRID_H -1\n",
    "    cell_coord_x = tf.cast(tf.reshape(tf.tile(tf.range(config.GRID_W), [config.GRID_H]), (1, config.GRID_H, config.GRID_W, 1, 1)), tf.float32)\n",
    "    cell_coord_y = tf.transpose(cell_coord_x, (0,2,1,3,4))\n",
    "    cell_coords = tf.tile(tf.concat([cell_coord_x, cell_coord_y], -1), [y_pred.shape[0], 1, 1, 5, 1])\n",
    "\n",
    "    # 0-GRID_W / GRID_H\n",
    "    anchors = config.ANCHORS\n",
    "\n",
    "    # 0-GRID_W / GRID_H\n",
    "    pred_xy = K.sigmoid(y_pred[:,:,:,:,0:2])\n",
    "    pred_xy = pred_xy + cell_coords\n",
    "    pred_wh = K.exp(y_pred[:,:,:,:,2:4]) * anchors\n",
    "\n",
    "    # 1、坐标损失（coordinate loss）\n",
    "    # 根据gt的wh计算系数，系数作用是w和h值越小，损失系数越大，可以更好地学习尺度较小的box\n",
    "    lambda_wh = K.expand_dims(2-(y_true_anchor_boxes[:,:,:,:,2]/config.GRID_W) * (y_true_anchor_boxes[:,:,:,:,3]/config.GRID_H))\n",
    "    detector_mask = K.cast(detector_mask, tf.float32)  # batch_size, GRID_W, GRID_H, n_anchors, 1\n",
    "    n_objs = K.sum(K.cast(detector_mask>0, tf.float32))\n",
    "    # 基于预测值计算坐标损失\n",
    "    y_txy = y_true_anchor_boxes[...,0:2] - cell_coords\n",
    "    y_twh = K.log(y_true_anchor_boxes[...,2:4]*1.0/anchors + 1e-16)\n",
    "    pred_txy = K.sigmoid(y_pred[:,:,:,:,0:2])\n",
    "    pred_twh = y_pred[:,:,:,:,2:4]\n",
    "    loss_xy = config.COORD_LAMBDA * K.sum(detector_mask * K.square(y_txy - pred_txy)) / (n_objs + 1e-6)\n",
    "    loss_wh = config.COORD_LAMBDA * K.sum(lambda_wh * detector_mask * K.square(y_twh - pred_twh)) / (n_objs + 1e-6)\n",
    "    loss_coord = loss_xy + loss_wh\n",
    "\n",
    "    # 2、类别损失\n",
    "    pred_class = K.softmax(y_pred[:,:,:,:,5:])\n",
    "    loss_cls = detector_mask * K.square(y_true_class_hot - pred_class)\n",
    "    loss_cls = config.CLASS_LAMBDA * K.sum(loss_cls) / (n_objs + 1e-6)\n",
    "\n",
    "    # 3、bounding box置信度损失\n",
    "    # 3.1、包含目标的预测的bounding box置信度损失\n",
    "    # 预测值和标记值的 IoU\n",
    "    x1 = y_true_anchor_boxes[...,0]\n",
    "    y1 = y_true_anchor_boxes[...,1]\n",
    "    w1 = y_true_anchor_boxes[...,2]\n",
    "    h1 = y_true_anchor_boxes[...,3]\n",
    "    x2 = pred_xy[...,0]\n",
    "    y2 = pred_xy[...,1]\n",
    "    w2 = pred_wh[...,0]\n",
    "    h2 = pred_wh[...,1]\n",
    "    iou = cal_iou(x1, y1, w1, h1, x2, y2, w2, h2)\n",
    "    iou = K.expand_dims(iou, -1)\n",
    "    # 使用 IoU 计算置信度的 target\n",
    "    pred_conf = K.sigmoid(y_pred[...,4:5])\n",
    "    loss_conf_obj = config.OBJECT_LAMBDA * K.sum(detector_mask * K.square(iou - pred_conf)) / (n_objs + 1e-6)\n",
    "    # 3.2、不包含目标的预测的bounding box置信度损失\n",
    "    # 预测值bounding box的xmin, ymin, xmax, ymax\n",
    "    pred_xy = K.expand_dims(pred_xy, 4)  # shape(batch_size, GRID_W, GRID_H, n_anchors, 1, 2)\n",
    "    pred_wh = K.expand_dims(pred_wh, 4)\n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_min = pred_xy - pred_wh_half\n",
    "    pred_max = pred_xy + pred_wh_half\n",
    "    # 标记值bounding box的xmin, ymin, xmax, ymax\n",
    "    true_boxes_shape = K.int_shape(y_true_boxes_all)\n",
    "    true_boxes_grid = K.reshape(y_true_boxes_all, [true_boxes_shape[0], 1, 1, 1, true_boxes_shape[1], true_boxes_shape[2]])\n",
    "    true_xy = true_boxes_grid[...,0:2]  # shape(batch_size, 1, 1, 1, max_annotation, 2)\n",
    "    true_wh = true_boxes_grid[...,2:4]  # shape(batch_size, 1, 1, 1, max_annotation, 2)\n",
    "    true_wh_half = true_wh * 0.5\n",
    "    true_min = true_xy - true_wh_half\n",
    "    true_max = true_xy + true_wh_half\n",
    "    # 计算每一个预测的box与所有标记的box的IoU，找出最大的IOU，如果小于阈值(0.6,并且不负责GT，根据1 - detector_mask)，该预测的box就加入noobj，计算置信度损失\n",
    "    intersect_min = K.maximum(pred_min, true_min)  # shape(batch_size, GRID_W, GRID_H, n_anchors, max_annotation, 2)\n",
    "    intersect_max = K.minimum(pred_max, true_max)  # shape(batch_size, GRID_W, GRID_H, n_anchors, max_annotation, 2)\n",
    "    intersect_wh = K.maximum(intersect_max - intersect_min, 0.)  # shape(batch_size, GRID_W, GRID_H, n_anchors, max_annotation, 1)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]  # shape(batch_size, GRID_W, GRID_H, n_anchors, max_annotation, 1)\n",
    "    pred_area = pred_wh[..., 0] * pred_wh[..., 1]  # shape(batch_size, GRID_W, GRID_H, n_anchors, 1, 1)\n",
    "    true_area = true_wh[..., 0] * true_wh[..., 1]  # shape(batch_size, GRID_W, GRID_H, n_anchors, max_annotation, 1)\n",
    "    union_area = pred_area + true_area - intersect_area\n",
    "    iou_score = intersect_area / union_area  # shape(batch_size, GRID_W, GRID_H, n_anchors, max_annotation, 1)\n",
    "    best_iou = K.max(iou_score, axis=4)  # Best IOU scores.\n",
    "    best_iou = K.expand_dims(best_iou)  # shape(batch_size, GRID_W, GRID_H, n_anchors, 1)\n",
    "    # 计算无目标损失\n",
    "    no_object_detection = K.cast(best_iou < 0.6, K.dtype(best_iou))\n",
    "    noobj_mask = no_object_detection * (1 - detector_mask)\n",
    "    n_noobj  = K.sum(tf.cast(noobj_mask  > 0.0, tf.float32))\n",
    "    loss_conf_noobj =  config.NOOBJECT_LAMBDA * K.sum(noobj_mask * K.square(-pred_conf)) / (n_noobj + 1e-6)\n",
    "    # 4、三种损失汇总\n",
    "    loss_conf = loss_conf_noobj + loss_conf_obj\n",
    "    loss = loss_conf + loss_cls + loss_coord\n",
    "    sub_loss = [loss_conf, loss_cls, loss_coord]\n",
    "    return loss, sub_loss\n",
    "\n",
    "def save_best_weights(model, name, val_loss_avg):\n",
    "    \"\"\"\n",
    "    保存最好的权重\n",
    "    \"\"\"\n",
    "    name = name + '_' + str(val_loss_avg) + '.h5'\n",
    "    path_name = os.path.join('weight/', name)\n",
    "    model.save_weights(path_name)\n",
    "    return path_name\n",
    "\n",
    "def log_loss(loss, val_loss, step):\n",
    "    tf.summary.scalar('loss', loss, step)\n",
    "    tf.summary.scalar('val_loss', val_loss, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6、开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "data_dir = 'VOCdevkit'\n",
    "val_set = {'VOC2012':['val']}\n",
    "train_set = {'VOC2007':['train', 'val', 'test'], 'VOC2012':['train']}\n",
    "\n",
    "batch_size = 6\n",
    "num_epochs = 30\n",
    "num_iterations = 30\n",
    "train_name = 'training_1'\n",
    "cfg = Config()\n",
    "model_weight_path = 'weight/yolo.weights'\n",
    "n_progress = 20  # 进度条份数\n",
    "\n",
    "# log（tensorboard）\n",
    "summery_writer = tf.summary.create_file_writer(os.path.join('logs/', train_name), flush_millis=20000)\n",
    "summery_writer.set_as_default()\n",
    "\n",
    "dataset_train = OB_tensor_slices_dataset(data_dir, train_set, batch_size, cfg, shuffle=True)\n",
    "dataset_val = OB_tensor_slices_dataset(data_dir, val_set, batch_size, cfg, shuffle=False)\n",
    "len_batches_train = tf.data.experimental.cardinality(dataset_train).numpy()\n",
    "len_batches_val = tf.data.experimental.cardinality(dataset_val).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 416, 416, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 416, 416, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_1 (BatchNormalization)     (None, 416, 416, 32) 128         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 416, 416, 32) 0           norm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 208, 208, 32) 0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 208, 208, 64) 18432       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_2 (BatchNormalization)     (None, 208, 208, 64) 256         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 208, 208, 64) 0           norm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 104, 104, 64) 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 104, 104, 128 73728       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_3 (BatchNormalization)     (None, 104, 104, 128 512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 104, 104, 128 0           norm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 104, 104, 64) 8192        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_4 (BatchNormalization)     (None, 104, 104, 64) 256         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 104, 104, 64) 0           norm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 104, 104, 128 73728       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_5 (BatchNormalization)     (None, 104, 104, 128 512         conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 104, 104, 128 0           norm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 52, 52, 128)  0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 52, 52, 256)  294912      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_6 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 52, 52, 256)  0           norm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 52, 52, 128)  32768       leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_7 (BatchNormalization)     (None, 52, 52, 128)  512         conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 52, 52, 128)  0           norm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 52, 52, 256)  294912      leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_8 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 52, 52, 256)  0           norm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 26, 26, 256)  0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                 (None, 26, 26, 512)  1179648     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_9 (BatchNormalization)     (None, 26, 26, 512)  2048        conv_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 26, 26, 512)  0           norm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_10 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 26, 26, 256)  0           norm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_11 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 26, 26, 512)  0           norm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_12 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 26, 26, 256)  0           norm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_13 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 26, 26, 512)  0           norm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 13, 13, 512)  0           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                (None, 13, 13, 1024) 4718592     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_14 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_15 (Conv2D)                (None, 13, 13, 512)  524288      leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_15 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 13, 13, 512)  0           norm_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 13, 13, 1024) 4718592     leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_16 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_17 (Conv2D)                (None, 13, 13, 512)  524288      leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_17 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 13, 13, 512)  0           norm_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_18 (Conv2D)                (None, 13, 13, 1024) 4718592     leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_18 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_19 (Conv2D)                (None, 13, 13, 1024) 9437184     leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_19 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_21 (Conv2D)                (None, 26, 26, 64)   32768       leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_21 (BatchNormalization)    (None, 26, 26, 64)   256         conv_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_20 (Conv2D)                (None, 13, 13, 1024) 9437184     leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 26, 26, 64)   0           norm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_20 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 13, 13, 256)  0           leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 13, 13, 1280) 0           lambda[0][0]                     \n",
      "                                                                 leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_22 (Conv2D)                (None, 13, 13, 1024) 11796480    concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "norm_22 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 13, 13, 1024) 0           leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_23 (Conv2D)                (None, 13, 13, 125)  128125      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 13, 13, 5, 25 0           conv_23[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 50,676,061\n",
      "Trainable params: 50,655,389\n",
      "Non-trainable params: 20,672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 准备模型\n",
    "weight_reader = WeightReader(model_weight_path)\n",
    "model = yolo(cfg)\n",
    "weight_reader.load_weights(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 准备训练\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "best_val_loss = 1e6\n",
    "initial_learning_rate = 2e-5\n",
    "decay_epochs = 30 * num_iterations\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=decay_epochs,\n",
    "    decay_rate=0.5,\n",
    "    staircase=True\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "train_layers = ['conv_22', 'norm_22', 'conv_23']\n",
    "train_vars = []\n",
    "for name in train_layers:\n",
    "     train_vars += model.get_layer(name).trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-14-16d13a207852>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m         \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdetector_mask\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_true_anchor_boxes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_true_class_hot\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_true_boxes_all\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcfg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mGradientTape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtape\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m             \u001B[0my_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m             \u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msub_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0myolo_loss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdetector_mask\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_true_anchor_boxes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_true_class_hot\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_true_boxes_all\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcfg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m             \u001B[0m_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mloss\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m0.01\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\why\\onedrive - stumail.ysu.edu.cn\\code\\python\\yolo\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1010\u001B[0m         with autocast_variable.enable_auto_cast_variables(\n\u001B[0;32m   1011\u001B[0m             self._compute_dtype_object):\n\u001B[1;32m-> 1012\u001B[1;33m           \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1013\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1014\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\why\\onedrive - stumail.ysu.edu.cn\\code\\python\\yolo\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, inputs, training, mask)\u001B[0m\n\u001B[0;32m    422\u001B[0m         \u001B[0ma\u001B[0m \u001B[0mlist\u001B[0m \u001B[0mof\u001B[0m \u001B[0mtensors\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mthere\u001B[0m \u001B[0mare\u001B[0m \u001B[0mmore\u001B[0m \u001B[0mthan\u001B[0m \u001B[0mone\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    423\u001B[0m     \"\"\"\n\u001B[1;32m--> 424\u001B[1;33m     return self._run_internal_graph(\n\u001B[0m\u001B[0;32m    425\u001B[0m         inputs, training=training, mask=mask)\n\u001B[0;32m    426\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\why\\onedrive - stumail.ysu.edu.cn\\code\\python\\yolo\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001B[0m in \u001B[0;36m_run_internal_graph\u001B[1;34m(self, inputs, training, mask)\u001B[0m\n\u001B[0;32m    558\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    559\u001B[0m         \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnode\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmap_arguments\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor_dict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 560\u001B[1;33m         \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnode\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    561\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    562\u001B[0m         \u001B[1;31m# Update tensor_dict.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\why\\onedrive - stumail.ysu.edu.cn\\code\\python\\yolo\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1010\u001B[0m         with autocast_variable.enable_auto_cast_variables(\n\u001B[0;32m   1011\u001B[0m             self._compute_dtype_object):\n\u001B[1;32m-> 1012\u001B[1;33m           \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1013\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1014\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\why\\onedrive - stumail.ysu.edu.cn\\code\\python\\yolo\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m    246\u001B[0m       \u001B[0minputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marray_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_compute_causal_padding\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    247\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 248\u001B[1;33m     \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_convolution_op\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkernel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    249\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    250\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muse_bias\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\why\\onedrive - stumail.ysu.edu.cn\\code\\python\\yolo\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    199\u001B[0m     \u001B[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    200\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 201\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    202\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    203\u001B[0m       \u001B[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\why\\onedrive - stumail.ysu.edu.cn\\code\\python\\yolo\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001B[0m in \u001B[0;36mconvolution_v2\u001B[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001B[0m\n\u001B[0;32m   1011\u001B[0m     \u001B[0mdilations\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1012\u001B[0m     name=None):\n\u001B[1;32m-> 1013\u001B[1;33m   return convolution_internal(\n\u001B[0m\u001B[0;32m   1014\u001B[0m       \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[1;31m# pylint: disable=redefined-builtin\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1015\u001B[0m       \u001B[0mfilters\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\why\\onedrive - stumail.ysu.edu.cn\\code\\python\\yolo\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001B[0m in \u001B[0;36mconvolution_internal\u001B[1;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001B[0m\n\u001B[0;32m   1141\u001B[0m         \u001B[0mop\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconv1d\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1142\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1143\u001B[1;33m       return op(\n\u001B[0m\u001B[0;32m   1144\u001B[0m           \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1145\u001B[0m           \u001B[0mfilters\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\why\\onedrive - stumail.ysu.edu.cn\\code\\python\\yolo\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001B[0m in \u001B[0;36m_conv2d_expanded_batch\u001B[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001B[0m\n\u001B[0;32m   2595\u001B[0m     \u001B[1;31m# We avoid calling squeeze_batch_dims to reduce extra python function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2596\u001B[0m     \u001B[1;31m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2597\u001B[1;33m     return gen_nn_ops.conv2d(\n\u001B[0m\u001B[0;32m   2598\u001B[0m         \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2599\u001B[0m         \u001B[0mfilter\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfilters\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\why\\onedrive - stumail.ysu.edu.cn\\code\\python\\yolo\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001B[0m in \u001B[0;36mconv2d\u001B[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001B[0m\n\u001B[0;32m    922\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mtld\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_eager\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    923\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 924\u001B[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001B[0m\u001B[0;32m    925\u001B[0m         \u001B[0m_ctx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"Conv2D\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfilter\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"strides\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstrides\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    926\u001B[0m         \u001B[1;34m\"use_cudnn_on_gpu\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0muse_cudnn_on_gpu\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"padding\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpadding\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = []\n",
    "    epoch_sub_loss = []\n",
    "    epoch_val_loss = []\n",
    "    epoch_val_sub_loss = []\n",
    "    print('\\nEpoch {} :'.format(epoch))\n",
    "\n",
    "    # train\n",
    "    for bs_idx, (x, y) in enumerate(dataset_train):\n",
    "        x, detector_mask, y_true_anchor_boxes, y_true_class_hot, y_true_boxes_all = transform(x, y, cfg)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x, training=True)\n",
    "            loss, sub_loss = yolo_loss(detector_mask, y_true_anchor_boxes, y_true_class_hot, y_true_boxes_all, y_pred, cfg)\n",
    "            _loss = loss * 0.01\n",
    "        grads = tape.gradient(_loss, train_vars)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, train_vars))\n",
    "        epoch_loss.append(loss)\n",
    "        epoch_sub_loss.append(sub_loss)\n",
    "        if (bs_idx + 1) % (math.ceil(num_iterations / n_progress)) == 0:\n",
    "            print('-', end='')\n",
    "        if (bs_idx + 1) == num_iterations:\n",
    "            break\n",
    "\n",
    "    # val\n",
    "    for bs_idx, (x,y) in enumerate(dataset_val):\n",
    "        x, detector_mask, y_true_anchor_boxes, y_true_class_hot, y_true_boxes_all = transform(x, y, cfg)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x, training=False)\n",
    "            loss, sub_loss = yolo_loss(detector_mask, y_true_anchor_boxes, y_true_class_hot, y_true_boxes_all, y_pred, cfg)\n",
    "        epoch_val_loss.append(loss)\n",
    "        epoch_val_sub_loss.append(sub_loss)\n",
    "        print('-', end='')\n",
    "        if (bs_idx+1)==1:\n",
    "            break\n",
    "\n",
    "    # 记录\n",
    "    loss_avg = np.mean(np.array(epoch_loss))\n",
    "    sub_loss_avg = np.mean(np.array(epoch_sub_loss), axis=0)\n",
    "    val_loss_avg = np.mean(np.array(epoch_val_loss))\n",
    "    val_sub_loss_avg = np.mean(np.array(epoch_val_sub_loss), axis=0)\n",
    "\n",
    "    log_loss(loss_avg, val_loss_avg, step=epoch)\n",
    "    train_loss_history.append(loss_avg)\n",
    "    val_loss_history.append(val_loss_avg)\n",
    "\n",
    "    if loss_avg < best_val_loss:\n",
    "        print('\\nfind better model for train')\n",
    "        best_model_path = save_best_weights(model, train_name+'_epoch%d' % epoch, loss_avg)\n",
    "        best_val_loss = loss_avg\n",
    "    print(' \\ntrain_loss={:.3f} (conf={:.3f}, class={:.3f}, coords={:.3f}), val_loss={:.3f} (conf={:.3f}, class={:.3f}, coords={:.3f})'.format(\n",
    "            loss_avg, sub_loss_avg[0], sub_loss_avg[1], sub_loss_avg[2], val_loss_avg, val_sub_loss_avg[0], val_sub_loss_avg[1], val_sub_loss_avg[2]))\n",
    "save_best_weights(model, train_name+'_epoch_final', 666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_img(img, boxes, labels, scores, config):\n",
    "    \"\"\"\n",
    "    画图\n",
    "    :param img: 图片\n",
    "    :param boxes: 物体位置box\n",
    "    :param labels: 标签\n",
    "    :param scores: 得分\n",
    "    :param config: 配置\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 画图\n",
    "    fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "    img = img.numpy()\n",
    "    boxes = boxes.numpy().reshape(-1, 4)\n",
    "    labels = labels.numpy()\n",
    "    scores = scores.numpy()\n",
    "\n",
    "    ax.show(img)\n",
    "    img_h, img_w = img.shape[0: 2]\n",
    "    colors = ['r', 'orange', 'g', 'b', 'pink', 'purple']\n",
    "    count = 0\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        cx, cy, w, h = box\n",
    "        if w * h <= 0:\n",
    "            continue\n",
    "        count += 1\n",
    "        cx = cx / config.GRID_W * img_w\n",
    "        cy = cy/config.GRID_H * img_h\n",
    "        w = w/config.GRID_W * img_w\n",
    "        h = h/config.GRID_H * img_h\n",
    "        name = cfg.VOC_LABEL_NAME[label+1]\n",
    "        ax.scatter(cx, cy, s=10, c='yellow')\n",
    "        text = ' No:%d' % count + '_'+ name + ' %.3f' % score\n",
    "        ax.text(cx-w/2, cy+h/2, text, fontdict={'size':15, 'color':colors[count-1]})\n",
    "        rect = patches.Rectangle((cx-w/2,cy-h/2), w, h, edgecolor=colors[count-1], linewidth=3.0, facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "def display_img(input_img, model, score_threshold, iou_threshold, config):\n",
    "    \"\"\"\n",
    "    把标签展示到图片上\n",
    "    :param input_img: 测试图片\n",
    "    :param model: yolo模型\n",
    "    :param score_threshold: 根据box_conf * box_class_prob筛选boxes\n",
    "    :param iou_threshold: 对boxes做NMS时的阈值\n",
    "    :param config: 配置\n",
    "    :return: box位置\n",
    "    \"\"\"\n",
    "    y_pred = model.predict_on_batch(tf.expand_dims(input_img, 0))\n",
    "    cell_coord_x = tf.cast(tf.reshape(tf.tile(tf.range(config.GRID_W), [config.GRID_H]), (1, config.GRID_H, config.GRID_W, 1, 1)), tf.float32)\n",
    "    cell_coord_y = tf.transpose(cell_coord_x, (0,2,1,3,4))\n",
    "    cell_coords = tf.tile(tf.concat([cell_coord_x, cell_coord_y], -1), [y_pred.shape[0], 1, 1, 5, 1])\n",
    "    anchors = config.ANCHORS\n",
    "\n",
    "    pred_xy = K.sigmoid(y_pred[:,:,:,:,0:2])\n",
    "    pred_xy = pred_xy + cell_coords\n",
    "    pred_wh = K.exp(y_pred[:,:,:,:,2:4]) * anchors\n",
    "\n",
    "    box_conf = K.sigmoid(y_pred[:,:,:,:,4:5])\n",
    "    box_class_prob = K.softmax(y_pred[:,:,:,:,5:])\n",
    "    box_xy1 = pred_xy - 0.5 * pred_wh\n",
    "    box_xy2 = pred_xy + 0.5 * pred_wh\n",
    "    boxes = K.concatenate((box_xy1, box_xy2), axis=-1)\n",
    "\n",
    "    box_scores = box_conf * box_class_prob\n",
    "\n",
    "    box_classes = K.argmax(box_scores, axis=-1) # 最好的分数的 index\n",
    "    box_class_scores = K.max(box_scores, axis=-1) # 最好的分数\n",
    "    prediction_mask = box_class_scores >= score_threshold\n",
    "    boxes = tf.boolean_mask(boxes, prediction_mask)\n",
    "    scores = tf.boolean_mask(box_class_scores, prediction_mask)\n",
    "    classes = tf.boolean_mask(box_classes, prediction_mask)\n",
    "\n",
    "    # NMS（非极大值抑制）\n",
    "    selected_idx = tf.image.non_max_suppression(boxes, scores, 50, iou_threshold=iou_threshold)\n",
    "    boxes = K.gather(boxes, selected_idx)  # [n, 4]\n",
    "    scores = K.gather(scores, selected_idx)  # [n,]\n",
    "    classes = K.gather(classes, selected_idx)  # [n,]\n",
    "    _boxes = K.stack((0.5*(boxes[:,0] + boxes[:,2]),\n",
    "                      0.5*(boxes[:,1] + boxes[:,3]),\n",
    "                      boxes[:,2] - boxes[:,0],\n",
    "                      boxes[:,3] - boxes[:,1]),\n",
    "                      axis=-1) # x1, y1, x2, y2 ==> cx, cy, w, h\n",
    "\n",
    "    return _boxes\n",
    "\n",
    "model.load_weights(best_model_path)\n",
    "for bs_idx, (x,y) in enumerate(dataset_val):\n",
    "    x, detector_mask, y_true_anchor_boxes, y_true_class_hot, y_true_boxes_all = transform(x, y, cfg)\n",
    "    score_threshold = 0.5\n",
    "    iou_threshold = 0.45\n",
    "\n",
    "    display_img(x[0], model, score_threshold, iou_threshold, cfg)\n",
    "    if (bs_idx + 1) == 10:\n",
    "        break\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "ax.plot(train_loss_history[10:])\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}